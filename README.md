# PDF Copilot - Copiloto Conversacional sobre Documentos

Un copiloto conversacional inteligente que permite subir hasta 5 archivos PDF y hacer preguntas en lenguaje natural sobre su contenido.

## ğŸŸ¢ Estado del Proyecto

**âœ… COMPLETAMENTE FUNCIONAL** - El sistema ha sido probado y estÃ¡ listo para uso en producciÃ³n.

### âœ… Funcionalidades Verificadas:
- âœ… Carga y procesamiento de documentos PDF
- âœ… ExtracciÃ³n de metadatos segura (compatible con ChromaDB)
- âœ… BÃºsqueda semÃ¡ntica con puntuaciones de relevancia corregidas
- âœ… GeneraciÃ³n de respuestas basadas en contexto
- âœ… IntegraciÃ³n completa Ollama + Llama 3.2
- âœ… Interfaz Streamlit totalmente funcional
- âœ… Vector store ChromaDB operativo

### ğŸ”§ Correcciones Recientes:
- âœ… Solucionado: Error de metadatos IndirectObject en ChromaDB
- âœ… Solucionado: Puntuaciones de relevancia negativas en bÃºsqueda semÃ¡ntica
- âœ… Optimizado: Filtros de relevancia mÃ¡s inclusivos
- âœ… Mejorado: Manejo robusto de errores en procesamiento de PDFs

## ğŸ¯ CaracterÃ­sticas Principales

- âœ… Subida de hasta 5 PDFs simultÃ¡neamente
- âœ… ExtracciÃ³n, divisiÃ³n y vectorizaciÃ³n inteligente del contenido
- âœ… Interfaz conversacional intuitiva
- âœ… OrquestaciÃ³n estructurada y extensible
- âœ… MÃºltiples opciones de LLM (OpenAI, Ollama, HuggingFace)
- âœ… Resumen automÃ¡tico de contenido
- âœ… Comparaciones entre documentos
- âœ… ClasificaciÃ³n por temas
- âœ… Despliegue local y con Docker

## ğŸ—ï¸ Arquitectura del Sistema

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/              # LÃ³gica central del sistema
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py    # Procesamiento de PDFs
â”‚   â”‚   â”œâ”€â”€ vectorstore.py      # Manejo del vector store
â”‚   â”‚   â”œâ”€â”€ llm_manager.py      # GestiÃ³n de mÃºltiples LLMs
â”‚   â”‚   â””â”€â”€ orchestrator.py     # OrquestaciÃ³n de flujos
â”‚   â”œâ”€â”€ agents/            # Agentes especializados
â”‚   â”‚   â”œâ”€â”€ summarizer.py       # Agente de resumen
â”‚   â”‚   â”œâ”€â”€ comparator.py       # Agente de comparaciÃ³n
â”‚   â”‚   â””â”€â”€ classifier.py       # Agente de clasificaciÃ³n
â”‚   â”œâ”€â”€ ui/               # Interfaz de usuario
â”‚   â”‚   â””â”€â”€ streamlit_app.py    # AplicaciÃ³n Streamlit
â”‚   â””â”€â”€ api/              # API REST
â”‚       â””â”€â”€ fastapi_app.py      # AplicaciÃ³n FastAPI
â”œâ”€â”€ data/                 # Datos y archivos temporales
â”œâ”€â”€ tests/               # Pruebas unitarias
â””â”€â”€ docker/             # ConfiguraciÃ³n Docker
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Core Technologies
- **Python 3.11+**: Lenguaje principal
- **LangChain**: Framework de orquestaciÃ³n
- **Chroma**: Vector store para embeddings
- **Streamlit**: Interfaz web interactiva
- **FastAPI**: API REST backend

### LLM Options
- **OpenAI GPT**: Para usuarios con API key
- **Ollama**: Modelos locales (Llama, Mistral)
- **HuggingFace**: Modelos open source

### Additional Tools
- **PyPDF2 / pdfplumber**: ExtracciÃ³n de texto PDF
- **sentence-transformers**: Embeddings locales
- **Docker**: ContainerizaciÃ³n
- **pytest**: Testing framework

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### OpciÃ³n 1: InstalaciÃ³n Local

1. **Clonar el repositorio:**
```bash
git clone <repository-url>
cd pdf-copilot
```

2. **Crear entorno virtual:**
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
```

3. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno:**
```bash
cp .env.example .env
# Editar .env con tus configuraciones
```

### OpciÃ³n 2: Docker

```bash
docker-compose up -d
```

## ğŸ® Uso

### Interfaz Streamlit
```bash
streamlit run src/ui/streamlit_app.py
```
Navegar a: `http://localhost:8501`

### API FastAPI
```bash
uvicorn src.api.fastapi_app:app --reload
```
DocumentaciÃ³n: `http://localhost:8000/docs`

## âš™ï¸ ConfiguraciÃ³n de LLMs

### OpenAI
```env
OPENAI_API_KEY=tu_api_key_aqui
LLM_PROVIDER=openai
```

### Ollama (Local)
```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Descargar modelo
ollama pull llama2
```

```env
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama2
```

### HuggingFace
```env
HUGGINGFACE_API_TOKEN=tu_token_aqui
LLM_PROVIDER=huggingface
HF_MODEL=microsoft/DialoGPT-medium
```

## ğŸ”§ JustificaciÃ³n de Elecciones TÃ©cnicas

### LangChain
- **Ventajas**: AbstracciÃ³n de LLMs, herramientas de orquestaciÃ³n robustas
- **Uso**: GestiÃ³n de flujos conversacionales y cadenas de procesamiento

### Chroma Vector Store
- **Ventajas**: Ligero, fÃ¡cil setup local, buen rendimiento
- **Uso**: Almacenamiento y bÃºsqueda semÃ¡ntica de embeddings

### Streamlit
- **Ventajas**: Desarrollo rÃ¡pido, interfaz reactiva, ideal para prototipos
- **Uso**: Interfaz principal del usuario

### FastAPI
- **Ventajas**: Alto rendimiento, documentaciÃ³n automÃ¡tica, type hints
- **Uso**: API REST para integraciones externas

## ğŸ”„ Flujo Conversacional

1. **Carga de Documentos**
   - ValidaciÃ³n de archivos PDF
   - ExtracciÃ³n de texto y metadatos
   - DivisiÃ³n en chunks optimizados

2. **Procesamiento**
   - GeneraciÃ³n de embeddings
   - Almacenamiento en vector store
   - CreaciÃ³n de Ã­ndices de bÃºsqueda

3. **OrquestaciÃ³n Conversacional**
   - AnÃ¡lisis de intenciÃ³n del usuario
   - BÃºsqueda semÃ¡ntica de contexto relevante
   - SelecciÃ³n de agente especializado

4. **GeneraciÃ³n de Respuesta**
   - ConstrucciÃ³n de prompt contextual
   - InvocaciÃ³n del LLM seleccionado
   - Post-procesamiento y formateo

## ğŸ§ª Testing

```bash
pytest tests/ -v
```

## ğŸ“ˆ Limitaciones Actuales

- MÃ¡ximo 5 PDFs por sesiÃ³n
- Soporte limitado a texto (no imÃ¡genes/tablas complejas)
- Modelos locales requieren hardware adecuado
- Rate limits en APIs externas

## ğŸ—ºï¸ Roadmap de Mejoras

### Corto Plazo
- [ ] Soporte para mÃ¡s formatos (DOCX, TXT)
- [ ] Mejora en extracciÃ³n de tablas
- [ ] Cache inteligente de resultados
- [ ] MÃ©tricas de rendimiento

### Medio Plazo
- [ ] AnÃ¡lisis de imÃ¡genes y diagramas
- [ ] IntegraciÃ³n con bases de datos externas
- [ ] Multiidioma avanzado
- [ ] Dashboard de analytics

### Largo Plazo
- [ ] Fine-tuning de modelos especÃ­ficos
- [ ] IntegraciÃ³n con sistemas empresariales
- [ ] Versioning de documentos
- [ ] ColaboraciÃ³n multi-usuario

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, revisa las guÃ­as de contribuciÃ³n y abre un issue antes de enviar un PR.

## ğŸ“„ Licencia

MIT License - ver archivo LICENSE para detalles.
